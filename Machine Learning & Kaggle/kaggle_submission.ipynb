{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Submission Lab\n",
    "\n",
    "Kaggle is a platform for data science competitions. In this lab, you'll learn how to participate in a Kaggle competition from start to finish.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Navigating Kaggle and finding competitions\n",
    "- Downloading and understanding competition data\n",
    "- Creating a submission file\n",
    "- Submitting predictions and viewing your score\n",
    "\n",
    "**Prerequisites:**\n",
    "- A Kaggle account ([kaggle.com](https://www.kaggle.com))\n",
    "- Completed the Basic ML Model lab (or equivalent experience)\n",
    "\n",
    "**Time:** ~30 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Finding a Competition\n",
    "\n",
    "### Where to Start\n",
    "\n",
    "1. Go to [kaggle.com/competitions](https://www.kaggle.com/competitions)\n",
    "2. Click on the **\"Getting Started\"** tab — these are beginner-friendly competitions\n",
    "\n",
    "### Recommended Beginner Competitions\n",
    "\n",
    "| Competition | Type | Description |\n",
    "|-------------|------|-------------|\n",
    "| [Titanic](https://www.kaggle.com/c/titanic) | Classification | Predict survival on the Titanic |\n",
    "| [House Prices](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) | Regression | Predict house sale prices |\n",
    "| [Digit Recognizer](https://www.kaggle.com/c/digit-recognizer) | Classification | Identify handwritten digits |\n",
    "\n",
    "For this lab, we'll walk through the **Titanic** competition — it's the classic beginner competition.\n",
    "\n",
    "### Join the Competition\n",
    "\n",
    "1. Go to [kaggle.com/c/titanic](https://www.kaggle.com/c/titanic)\n",
    "2. Click **\"Join Competition\"**\n",
    "3. Accept the rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Understanding the Competition\n",
    "\n",
    "Every Kaggle competition page has important tabs:\n",
    "\n",
    "| Tab | What it contains |\n",
    "|-----|------------------|\n",
    "| **Overview** | Competition description, prizes, timeline |\n",
    "| **Data** | Download data, description of features |\n",
    "| **Code** | Public notebooks from other participants |\n",
    "| **Discussion** | Q&A and tips from the community |\n",
    "| **Leaderboard** | Rankings based on submissions |\n",
    "| **Rules** | Submission limits, team rules, etc. |\n",
    "\n",
    "### The Titanic Challenge\n",
    "\n",
    "**Goal:** Predict which passengers survived the Titanic disaster.\n",
    "\n",
    "**Data files:**\n",
    "- `train.csv` — Training data with survival labels (what you train on)\n",
    "- `test.csv` — Test data without labels (what you predict)\n",
    "- `gender_submission.csv` — Example submission file showing the format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Getting the Data\n",
    "\n",
    "You have two options:\n",
    "\n",
    "### Option A: Download from Kaggle Website\n",
    "\n",
    "1. Go to the Data tab\n",
    "2. Click \"Download All\"\n",
    "3. Extract the zip file to your working directory\n",
    "\n",
    "### Option B: Use Kaggle API (Recommended)\n",
    "\n",
    "First, set up the Kaggle API:\n",
    "\n",
    "1. Go to [kaggle.com/account](https://www.kaggle.com/account)\n",
    "2. Scroll to \"API\" section\n",
    "3. Click \"Create New API Token\"\n",
    "4. This downloads `kaggle.json`\n",
    "5. Place it in `~/.kaggle/` (Linux/Mac) or `C:\\Users\\<username>\\.kaggle\\` (Windows)\n",
    "\n",
    "Then install and use the API:\n",
    "\n",
    "```bash\n",
    "pip install kaggle\n",
    "kaggle competitions download -c titanic\n",
    "unzip titanic.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Load and Explore the Data\n",
    "\n",
    "Let's load the Titanic data. If you don't have it downloaded, we'll create sample data that mirrors the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Libraries imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load the actual Titanic data\n",
    "# If files don't exist, we'll create synthetic data with the same structure\n",
    "\n",
    "try:\n",
    "    train = pd.read_csv('train.csv')\n",
    "    test = pd.read_csv('test.csv')\n",
    "    print(\"Loaded Kaggle Titanic data!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Titanic files not found. Creating synthetic data for demonstration...\")\n",
    "    print(\"(Download the real data from kaggle.com/c/titanic for the actual competition)\")\n",
    "    \n",
    "    # Create synthetic Titanic-like data\n",
    "    np.random.seed(42)\n",
    "    n_train, n_test = 891, 418\n",
    "    \n",
    "    def create_titanic_data(n, include_survived=True):\n",
    "        data = {\n",
    "            'PassengerId': range(1, n + 1),\n",
    "            'Pclass': np.random.choice([1, 2, 3], n, p=[0.24, 0.21, 0.55]),\n",
    "            'Sex': np.random.choice(['male', 'female'], n, p=[0.65, 0.35]),\n",
    "            'Age': np.random.normal(30, 14, n).clip(0.5, 80),\n",
    "            'SibSp': np.random.choice([0, 1, 2, 3, 4], n, p=[0.68, 0.23, 0.05, 0.02, 0.02]),\n",
    "            'Parch': np.random.choice([0, 1, 2, 3], n, p=[0.76, 0.13, 0.09, 0.02]),\n",
    "            'Fare': np.random.exponential(30, n).clip(0, 500),\n",
    "            'Embarked': np.random.choice(['S', 'C', 'Q'], n, p=[0.72, 0.19, 0.09])\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        if include_survived:\n",
    "            survival_prob = 0.38\n",
    "            survival_prob += np.where(df['Sex'] == 'female', 0.35, -0.15)\n",
    "            survival_prob += np.where(df['Pclass'] == 1, 0.15, np.where(df['Pclass'] == 3, -0.15, 0))\n",
    "            survival_prob += np.where(df['Age'] < 16, 0.1, 0)\n",
    "            survival_prob = np.clip(survival_prob, 0.05, 0.95)\n",
    "            df['Survived'] = (np.random.random(n) < survival_prob).astype(int)\n",
    "        \n",
    "        df.loc[np.random.choice(n, int(n * 0.2), replace=False), 'Age'] = np.nan\n",
    "        df.loc[np.random.choice(n, int(n * 0.002), replace=False), 'Embarked'] = np.nan\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    train = create_titanic_data(n_train, include_survived=True)\n",
    "    test = create_titanic_data(n_test, include_survived=False)\n",
    "    test['PassengerId'] = range(892, 892 + n_test)\n",
    "    \n",
    "print(f\"\\nTraining data: {train.shape}\")\n",
    "print(f\"Test data: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the training data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "print(\"Missing Values:\")\n",
    "print(train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival rate\n",
    "print(f\"Overall survival rate: {train['Survived'].mean():.2%}\")\n",
    "print(\"\\nSurvival by Sex:\")\n",
    "print(train.groupby('Sex')['Survived'].mean())\n",
    "print(\"\\nSurvival by Pclass:\")\n",
    "print(train.groupby('Pclass')['Survived'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Prepare the Data\n",
    "\n",
    "We need to handle missing values and convert categorical variables to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_titanic(df):\n",
    "    \"\"\"\n",
    "    Preprocess Titanic data.\n",
    "    Returns a copy with features ready for modeling.\n",
    "    \"\"\"\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Fill missing Age with median\n",
    "    data['Age'] = data['Age'].fillna(data['Age'].median())\n",
    "    \n",
    "    # Fill missing Embarked with mode\n",
    "    data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
    "    \n",
    "    # Fill missing Fare with median\n",
    "    data['Fare'] = data['Fare'].fillna(data['Fare'].median())\n",
    "    \n",
    "    # Convert Sex to numeric\n",
    "    data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
    "    \n",
    "    # Convert Embarked to numeric\n",
    "    data['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "    \n",
    "    # Select features\n",
    "    features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "    \n",
    "    return data[features]\n",
    "\n",
    "# Preprocess both train and test\n",
    "X_train_full = preprocess_titanic(train)\n",
    "X_test_final = preprocess_titanic(test)\n",
    "y_train_full = train['Survived']\n",
    "\n",
    "print(\"Preprocessing complete!\")\n",
    "print(f\"Training features shape: {X_train_full.shape}\")\n",
    "print(f\"Test features shape: {X_test_final.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Train and Validate Locally\n",
    "\n",
    "Before submitting to Kaggle, validate your model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(model, X_train_full, y_train_full, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Train Final Model and Create Submission\n",
    "\n",
    "Train on ALL training data and create predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on full training data\n",
    "final_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "final_model.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Make predictions on test set\n",
    "test_predictions = final_model.predict(X_test_final)\n",
    "\n",
    "print(f\"Predictions generated: {len(test_predictions)} rows\")\n",
    "print(f\"Predicted survival: {test_predictions.sum()} / {len(test_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': test_predictions\n",
    "})\n",
    "\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\nSubmission saved to 'submission.csv'!\")\n",
    "\n",
    "# Verify\n",
    "print(f\"File shape: {pd.read_csv('submission.csv').shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Submit to Kaggle\n",
    "\n",
    "### Option A: Website Upload\n",
    "\n",
    "1. Go to [kaggle.com/c/titanic](https://www.kaggle.com/c/titanic)\n",
    "2. Click **\"Submit Predictions\"**\n",
    "3. Upload your `submission.csv` file\n",
    "4. Add a description (e.g., \"Random Forest, basic features\")\n",
    "5. Click **\"Make Submission\"**\n",
    "\n",
    "### Option B: Kaggle API\n",
    "\n",
    "```bash\n",
    "kaggle competitions submit -c titanic -f submission.csv -m \"Random Forest baseline\"\n",
    "```\n",
    "\n",
    "### After Submitting\n",
    "\n",
    "- You'll see your score on the **public leaderboard**\n",
    "- The public leaderboard uses a portion of the test data\n",
    "- Final rankings use the **private leaderboard** (revealed when competition ends)\n",
    "- You can submit multiple times (check rules for daily limits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Improving Your Score\n",
    "\n",
    "### Feature Engineering Ideas\n",
    "\n",
    "```python\n",
    "# Family size\n",
    "data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "data['IsAlone'] = (data['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# Extract title from name\n",
    "data['Title'] = data['Name'].str.extract(' ([A-Za-z]+)\\\\.', expand=False)\n",
    "\n",
    "# Age bins\n",
    "data['AgeBin'] = pd.cut(data['Age'], bins=[0, 12, 20, 40, 60, 100], labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "# Fare per person\n",
    "data['FarePerPerson'] = data['Fare'] / data['FamilySize']\n",
    "```\n",
    "\n",
    "### Try Different Models\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "```\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)\n",
    "grid_search.fit(X_train_full, y_train_full)\n",
    "\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_:.4f}\")\n",
    "```\n",
    "\n",
    "### Learn from Others\n",
    "\n",
    "- Check the **Code** tab on Kaggle for public notebooks\n",
    "- Read top solutions after competitions end\n",
    "- Join the **Discussion** forum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Kaggle Workflow\n",
    "\n",
    "1. **Find and join** a competition\n",
    "2. **Download** and explore the data\n",
    "3. **Preprocess** the data\n",
    "4. **Train and validate** locally (use cross-validation!)\n",
    "5. **Train final model** on all training data\n",
    "6. **Create submission** file in the required format\n",
    "7. **Submit** and check your score\n",
    "8. **Iterate** — try new features, models, parameters\n",
    "\n",
    "### Submission File Format\n",
    "\n",
    "Always check the competition's required format! For Titanic:\n",
    "\n",
    "```\n",
    "PassengerId,Survived\n",
    "892,0\n",
    "893,1\n",
    "894,0\n",
    "...\n",
    "```\n",
    "\n",
    "### Tips\n",
    "\n",
    "- **Start simple** — Get a baseline submission first\n",
    "- **Validate locally** — Don't waste submissions on obvious bugs\n",
    "- **Read the rules** — Understand evaluation metrics and limits\n",
    "- **Learn from others** — Public notebooks are a goldmine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. **Submit to Titanic:** Use this notebook to make your first submission\n",
    "\n",
    "2. **Try House Prices:** Apply similar steps to the House Prices regression competition\n",
    "\n",
    "3. **Feature engineering:** Add 2-3 new features and see if your score improves\n",
    "\n",
    "4. **Model comparison:** Try at least 3 different models and compare their cross-validation scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Section\n",
    "\n",
    "Continue to: **[Presenting Projects and Pitching](../04-presenting-projects/)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
